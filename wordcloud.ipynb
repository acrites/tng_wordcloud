{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_transcripts(output_dir):\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    for episode_num in list(range(101,278)):\n",
    "        url = 'http://www.chakoteya.net/NextGen/{}.htm'.format(episode_num)\n",
    "        html = requests.get(url).content.decode('latin-1')\n",
    "        with open(os.path.join(output_dir, 'script{}.htm'.format(episode_num)), 'wb+') as f:\n",
    "            f.write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_lines(episode):\n",
    "    lines = []\n",
    "    # skip the airdate and other metadata\n",
    "    for line in episode.split('<br>')[3:]:\n",
    "        new_line = re.sub('\\\\r\\\\n', ' ', line)\n",
    "        new_line = re.sub('&nbsp;', ' ', new_line)\n",
    "        # Remove HTML tags\n",
    "        new_line = re.sub('<[^>]+>', '', new_line)\n",
    "        # Remove scene descriptions (in parens and brackets)\n",
    "        new_line = re.sub('\\([^)]+\\)', '', new_line)\n",
    "        new_line = re.sub('\\s*\\[[^\\]]+\\]', '', new_line)\n",
    "        new_line = re.sub('&lt;.*', '', new_line)\n",
    "        new_line = new_line.strip()\n",
    "        if len(new_line) > 0:\n",
    "            lines.append(new_line)\n",
    "    return lines\n",
    "\n",
    "def get_lines(script_dir, parse_file_function=get_all_lines):\n",
    "    all_lines = []\n",
    "    for episode_num in [101] + range(103, 278):\n",
    "        try:\n",
    "            with open(os.path.join(script_dir, 'script{}.htm'.format(episode_num)), 'r') as f:\n",
    "                html = f.read()\n",
    "                all_lines += parse_file_function(html)\n",
    "        except:\n",
    "            print \"could not open episode\", episode_num\n",
    "    return all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_two_word_phrases(lines, output_filename=\"two_word_phrases.txt\"):\n",
    "    phrase = defaultdict(defaultdict)\n",
    "    previous = \"\"\n",
    "    for line in lines:\n",
    "        try:\n",
    "            for word, tag in nltk.pos_tag(nltk.word_tokenize(line)):\n",
    "                word = word.lower()\n",
    "                if word in [\"\\'s\", \"n\\'t\", \"\\'ll\", \"\\'ve\", \"\\'m\", \"\\'re\", \"\\'d\"]:\n",
    "                    previous += word\n",
    "                    continue\n",
    "                if tag not in [',', '.', ':']:\n",
    "                    if previous in phrase:\n",
    "                        phrase[previous][word] += 1\n",
    "                    else:\n",
    "                        phrase[previous] = defaultdict(int)\n",
    "                    previous = word\n",
    "        except:\n",
    "            print line\n",
    "\n",
    "    sayings = []\n",
    "    for first_word, second_dict in phrase.iteritems():\n",
    "        for second_word in second_dict.iterkeys():\n",
    "            if phrase[first_word][second_word] > 10:\n",
    "                sayings.append([phrase[first_word][second_word], \" \".join([first_word,second_word])])\n",
    "    sayings.sort(reverse=True)\n",
    "    with open(output_filename, 'w') as f:\n",
    "        for v,k in sayings:\n",
    "            f.write(k+' '+str(v)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_word_counts(lines):\n",
    "    all_words = defaultdict(int)\n",
    "    for line in lines:\n",
    "        try:\n",
    "            tokens = nltk.pos_tag(nltk.word_tokenize(line))\n",
    "            # TODO: I had tried to use stemming here to collate things like weapon and weapons,\n",
    "            #       but couldn't really get it to work well.f\n",
    "            for word, tag in tokens:\n",
    "                if tag not in [',', '.', ':']:\n",
    "                    word_stem = word.lower()\n",
    "                    all_words[word_stem] += 1\n",
    "        except:\n",
    "            print line\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_sorted_words(word_dict, out_filename=\"sorted_word_list.txt\"):\n",
    "    sorted_words = [(v,k) for (k,v) in word_dict.iteritems()]\n",
    "    sorted_words.sort(reverse=True)\n",
    "    words = [(k,v) for (v,k) in sorted_words]\n",
    "    with open(out_filename, 'w') as f:\n",
    "        for k,v in words:\n",
    "            f.write(k+' '+str(v)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_wordcloud(word_filename, mask, font, show_image=True, show_mask=False):\n",
    "\n",
    "    # This function chooses colors randomly from the given palette.\n",
    "    def tng_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        # Color palette for the ship's computer displays.\n",
    "        palette = [\"rgb(255, 153, 0)\", \"rgb(204, 153, 204)\", \"rgb(153, 153, 204)\",\n",
    "                   \"rgb(204, 102, 102)\", \"rgb(255, 204, 153)\", \"rgb(153, 153, 255)\",\n",
    "                   \"rgb(255, 153, 102)\", \"rgb(204, 102, 153)\"]\n",
    "        return palette[random.randint(0, len(palette)-1)]\n",
    "\n",
    "    tng_mask = imread(mask)\n",
    "    wc = WordCloud(background_color=\"black\", max_words=250, mask=tng_mask, color_func=tng_color_func,\n",
    "                   font_path=font, max_font_size=80, scale=4, width=2700, height=4800,\n",
    "                   prefer_horizontal=0.5, ranks_only=False)\n",
    "\n",
    "    word_list = []\n",
    "    with open(word_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split(' ')\n",
    "            word = \" \".join(tokens[:-1])\n",
    "            count = int(tokens[-1].strip())\n",
    "            word_list.append([word, count])\n",
    "\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(word_list)\n",
    "\n",
    "    # store to file\n",
    "    wc.to_file(\"test.png\")\n",
    "\n",
    "    # show the resulting word cloud\n",
    "    if show_image:\n",
    "        plt.imshow(wc)\n",
    "        plt.axis(\"off\")\n",
    "        if show_mask:\n",
    "            plt.figure()\n",
    "            plt.imshow(tng_mask, cmap=plt.cm.gray)\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_lines = get_lines(\"script_dir\", get_all_lines)\n",
    "word_counts = get_word_counts(all_lines)\n",
    "write_sorted_words(word_counts, out_filename=\"all_cast_words.txt\")\n",
    "get_two_word_phrases(all_lines, out_filename=\"two_word_phrases.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_wordcloud(\"sorted_cloud_words.txt\", \"tng_emblem.png\", \"TNG_Title.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
